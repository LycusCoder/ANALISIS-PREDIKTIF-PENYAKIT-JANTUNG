{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59773b3e-76dc-4c34-a2ff-dde4831b89ff",
   "metadata": {},
   "source": [
    "# backend/train_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7cacb0-3f51-4ff3-bfab-7002c079e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3faf3-df68-47f5-a48c-50ed50088dba",
   "metadata": {},
   "source": [
    "# Path ke dataset kamu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1199c12-e70a-4483-ae47-5cbfe3800cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"data/heart_disease_uci.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a98991-aab9-429e-ab00-b1b2a53792b5",
   "metadata": {},
   "source": [
    "# Memuat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc76320-1184-47f2-897d-956e030b8764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 5 Baris Pertama Dataset =====\n",
      "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
      "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
      "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
      "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
      "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
      "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
      "\n",
      "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
      "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
      "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
      "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
      "3          normal   187.0  False      3.5  downsloping  0.0   \n",
      "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
      "\n",
      "                thal  num  \n",
      "0       fixed defect    0  \n",
      "1             normal    2  \n",
      "2  reversable defect    1  \n",
      "3             normal    0  \n",
      "4             normal    0  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File dataset tidak ditemukan di {DATASET_PATH}\")\n",
    "    exit()\n",
    "\n",
    "print(\"===== 5 Baris Pertama Dataset =====\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb7b977a-2bb0-4547-89e7-c11c6bb3406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Informasi Dataset =====\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    object \n",
      " 3   dataset   920 non-null    object \n",
      " 4   cp        920 non-null    object \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       830 non-null    object \n",
      " 8   restecg   918 non-null    object \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     865 non-null    object \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     611 non-null    object \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      434 non-null    object \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 115.1+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Informasi Dataset =====\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7a552a-e419-41cc-94c2-32f06dff8c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Deskripsi Statistik Dataset =====\n",
      "                id         age   sex    dataset            cp    trestbps  \\\n",
      "count   920.000000  920.000000   920        920           920  861.000000   \n",
      "unique         NaN         NaN     2          4             4         NaN   \n",
      "top            NaN         NaN  Male  Cleveland  asymptomatic         NaN   \n",
      "freq           NaN         NaN   726        304           496         NaN   \n",
      "mean    460.500000   53.510870   NaN        NaN           NaN  132.132404   \n",
      "std     265.725422    9.424685   NaN        NaN           NaN   19.066070   \n",
      "min       1.000000   28.000000   NaN        NaN           NaN    0.000000   \n",
      "25%     230.750000   47.000000   NaN        NaN           NaN  120.000000   \n",
      "50%     460.500000   54.000000   NaN        NaN           NaN  130.000000   \n",
      "75%     690.250000   60.000000   NaN        NaN           NaN  140.000000   \n",
      "max     920.000000   77.000000   NaN        NaN           NaN  200.000000   \n",
      "\n",
      "              chol    fbs restecg      thalch  exang     oldpeak slope  \\\n",
      "count   890.000000    830     918  865.000000    865  858.000000   611   \n",
      "unique         NaN      2       3         NaN      2         NaN     3   \n",
      "top            NaN  False  normal         NaN  False         NaN  flat   \n",
      "freq           NaN    692     551         NaN    528         NaN   345   \n",
      "mean    199.130337    NaN     NaN  137.545665    NaN    0.878788   NaN   \n",
      "std     110.780810    NaN     NaN   25.926276    NaN    1.091226   NaN   \n",
      "min       0.000000    NaN     NaN   60.000000    NaN   -2.600000   NaN   \n",
      "25%     175.000000    NaN     NaN  120.000000    NaN    0.000000   NaN   \n",
      "50%     223.000000    NaN     NaN  140.000000    NaN    0.500000   NaN   \n",
      "75%     268.000000    NaN     NaN  157.000000    NaN    1.500000   NaN   \n",
      "max     603.000000    NaN     NaN  202.000000    NaN    6.200000   NaN   \n",
      "\n",
      "                ca    thal         num  \n",
      "count   309.000000     434  920.000000  \n",
      "unique         NaN       3         NaN  \n",
      "top            NaN  normal         NaN  \n",
      "freq           NaN     196         NaN  \n",
      "mean      0.676375     NaN    0.995652  \n",
      "std       0.935653     NaN    1.142693  \n",
      "min       0.000000     NaN    0.000000  \n",
      "25%       0.000000     NaN    0.000000  \n",
      "50%       0.000000     NaN    1.000000  \n",
      "75%       1.000000     NaN    2.000000  \n",
      "max       3.000000     NaN    4.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Deskripsi Statistik Dataset =====\")\n",
    "print(df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2f808a-b7bf-4056-bba9-0c5e6bcb7faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Jumlah Nilai Kosong per Kolom =====\n",
      "id            0\n",
      "age           0\n",
      "sex           0\n",
      "dataset       0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs          90\n",
      "restecg       2\n",
      "thalch       55\n",
      "exang        55\n",
      "oldpeak      62\n",
      "slope       309\n",
      "ca          611\n",
      "thal        486\n",
      "num           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Jumlah Nilai Kosong per Kolom =====\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8ed3d44-7e88-41f5-a1f6-108a8a28403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Jumlah Data Unik per Kolom =====\n",
      "Kolom 'id': 920 nilai unik\n",
      "Kolom 'age': 50 nilai unik\n",
      "Kolom 'sex': 2 nilai unik\n",
      "Kolom 'dataset': 4 nilai unik\n",
      "Kolom 'cp': 4 nilai unik\n",
      "Kolom 'trestbps': 61 nilai unik\n",
      "Kolom 'chol': 217 nilai unik\n",
      "Kolom 'fbs': 2 nilai unik\n",
      "Kolom 'restecg': 3 nilai unik\n",
      "Kolom 'thalch': 119 nilai unik\n",
      "Kolom 'exang': 2 nilai unik\n",
      "Kolom 'oldpeak': 53 nilai unik\n",
      "Kolom 'slope': 3 nilai unik\n",
      "Kolom 'ca': 4 nilai unik\n",
      "Kolom 'thal': 3 nilai unik\n",
      "Kolom 'num': 5 nilai unik\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Jumlah Data Unik per Kolom =====\")\n",
    "for col in df.columns:\n",
    "    print(f\"Kolom '{col}': {df[col].nunique()} nilai unik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305cda73-3dc8-475e-8142-e38ec59f503c",
   "metadata": {},
   "source": [
    "# Memuat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ae1db1-cc67-4896-bb07-4a9a110b879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Saat memuat, kita bisa langsung definisikan nilai '?' sebagai NaN\n",
    "    df_raw = pd.read_csv(DATASET_PATH, na_values=['?'])\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File dataset tidak ditemukan di {DATASET_PATH}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f041ee26-15c7-4494-81d0-51e4629d2eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Informasi Dataset Setelah na_values='?' =====\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        920 non-null    int64  \n",
      " 1   age       920 non-null    int64  \n",
      " 2   sex       920 non-null    object \n",
      " 3   dataset   920 non-null    object \n",
      " 4   cp        920 non-null    object \n",
      " 5   trestbps  861 non-null    float64\n",
      " 6   chol      890 non-null    float64\n",
      " 7   fbs       830 non-null    object \n",
      " 8   restecg   918 non-null    object \n",
      " 9   thalch    865 non-null    float64\n",
      " 10  exang     865 non-null    object \n",
      " 11  oldpeak   858 non-null    float64\n",
      " 12  slope     611 non-null    object \n",
      " 13  ca        309 non-null    float64\n",
      " 14  thal      434 non-null    object \n",
      " 15  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 115.1+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Informasi Dataset Setelah na_values='?' =====\")\n",
    "df_raw.info() # Cek ulang Dtype dan Non-Null Count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a05cf48c-0702-420f-b284-bd81e177d16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Jumlah Nilai Kosong per Kolom Setelah na_values='?' =====\n",
      "id            0\n",
      "age           0\n",
      "sex           0\n",
      "dataset       0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs          90\n",
      "restecg       2\n",
      "thalch       55\n",
      "exang        55\n",
      "oldpeak      62\n",
      "slope       309\n",
      "ca          611\n",
      "thal        486\n",
      "num           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Jumlah Nilai Kosong per Kolom Setelah na_values='?' =====\")\n",
    "print(df_raw.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0afb29-b04d-4df4-a0f2-de4eba88e5d0",
   "metadata": {},
   "source": [
    "# 1. Fokus pada dataset 'Cleveland'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71b67ca0-a01c-4c33-8477-3d2140763156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribusi nilai unik kolom 'dataset' sebelum filter:\n",
      "dataset\n",
      "Cleveland        304\n",
      "Hungary          293\n",
      "VA Long Beach    200\n",
      "Switzerland      123\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Jumlah data setelah filter 'Cleveland': 304\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nDistribusi nilai unik kolom 'dataset' sebelum filter:\\n{df_raw['dataset'].value_counts()}\")\n",
    "df = df_raw[df_raw['dataset'] == 'Cleveland'].copy() # .copy() untuk menghindari SettingWithCopyWarning\n",
    "print(f\"\\nJumlah data setelah filter 'Cleveland': {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43a5b4-666d-49c9-a818-bf805aea3278",
   "metadata": {},
   "source": [
    "# 2. Drop kolom yang tidak relevan\n",
    "# Kolom 'id' dan 'dataset' (karena sudah difilter) tidak lagi relevan untuk model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0deda6e3-10a3-4869-8856-00ff66b4b6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kolom setelah drop 'id' dan 'dataset': ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['id', 'dataset']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "print(f\"\\nKolom setelah drop 'id' dan 'dataset': {df.columns.tolist()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d30050-3f06-4971-9827-cef1e19ae310",
   "metadata": {},
   "source": [
    "# 3. Cek ulang missing values setelah filter dan drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf91979-720a-41cc-9d98-b658b5720386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Jumlah Nilai Kosong (Cleveland) Setelah Drop Kolom =====\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalch      0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       1\n",
      "ca          5\n",
      "thal        3\n",
      "num         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Jumlah Nilai Kosong (Cleveland) Setelah Drop Kolom =====\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7dfeb-713d-40b6-bb7f-6ad1dd281c9d",
   "metadata": {},
   "source": [
    "# 4. Konversi target 'num' menjadi biner\n",
    "### 0 = tidak ada penyakit, >0 = ada penyakit (ubah ke 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a439694-46c7-428a-ac1e-c2a2d7d30829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Distribusi Target Setelah Konversi Biner =====\n",
      "target\n",
      "0    165\n",
      "1    139\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df.drop(columns=['num'], inplace=True) # Drop kolom 'num' asli\n",
    "print(\"\\n===== Distribusi Target Setelah Konversi Biner =====\")\n",
    "print(df['target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a25399-7de5-48a6-807d-3a7f77f5d203",
   "metadata": {},
   "source": [
    "# 5. Penanganan Tipe Data yang Seharusnya Numerik tapi Dibaca Object karena '?'\n",
    "### Kolom 'ca' dan 'thal' sering punya '?' yang membuatnya object.\n",
    "### read_csv dengan na_values=['?'] sudah harusnya mengubah '?' menjadi NaN,\n",
    "### dan Pandas akan mencoba infer tipe data. Kita cek lagi.\n",
    "### Jika 'ca' dan 'thal' masih object, kita perlu konversi manual ke float setelah imputasi.\n",
    "### Untuk 'fbs' dan 'exang' yang TRUE/FALSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4252e7f8-a8e7-4e2f-bd52-c5e7a1541cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Dtypes setelah konversi boolean (fbs, exang) =====\n",
      "age           int64\n",
      "sex          object\n",
      "cp           object\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs         float64\n",
      "restecg      object\n",
      "thalch      float64\n",
      "exang       float64\n",
      "oldpeak     float64\n",
      "slope        object\n",
      "ca          float64\n",
      "thal         object\n",
      "target        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "bool_map = {True: 1, False: 0, np.nan: np.nan} # Mapping untuk True/False ke 1/0, NaN tetap NaN\n",
    "df['fbs'] = df['fbs'].map(bool_map)\n",
    "df['exang'] = df['exang'].map(bool_map)\n",
    "\n",
    "print(\"\\n===== Dtypes setelah konversi boolean (fbs, exang) =====\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cfd3ba5-fe0e-4fd9-b956-3d45325593c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TAHAP 2: Imputasi Missing Values (Cleveland) =====\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== TAHAP 2: Imputasi Missing Values (Cleveland) =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e1b45-6813-491c-9215-9735d1edd81a",
   "metadata": {},
   "source": [
    "# Cek tipe data sebelum imputasi untuk kolom dengan missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31b7f31d-2cfd-4599-86d0-eab70f4a599c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtype 'slope' sebelum imputasi: object\n",
      "Dtype 'ca' sebelum imputasi: float64\n",
      "Dtype 'thal' sebelum imputasi: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Dtype 'slope' sebelum imputasi:\", df['slope'].dtype)\n",
    "print(\"Dtype 'ca' sebelum imputasi:\", df['ca'].dtype)\n",
    "print(\"Dtype 'thal' sebelum imputasi:\", df['thal'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e75c20-c948-47d2-b3a7-9c6ed1fe7415",
   "metadata": {},
   "source": [
    "### Imputasi dengan modus untuk 'slope', 'ca', dan 'thal' karena jumlah missing sedikit\n",
    "### dan 'ca' serta 'thal' bisa dianggap kategorikal/diskrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebe5b850-d3f7-4bdc-b1f2-fe336ed92cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom 'slope' diimputasi dengan modus: upsloping\n",
      "Kolom 'ca' diimputasi dengan modus: 0.0\n",
      "Kolom 'thal' diimputasi dengan modus: normal\n",
      "\n",
      "===== Jumlah Nilai Kosong Setelah Imputasi (Cleveland) =====\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalch      0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in ['slope', 'ca', 'thal']:\n",
    "    if df[col].isnull().any():\n",
    "        mode_val = df[col].mode()[0] # Ambil modus pertama jika ada lebih dari satu\n",
    "        df[col] = df[col].fillna(mode_val)\n",
    "        print(f\"Kolom '{col}' diimputasi dengan modus: {mode_val}\")\n",
    "\n",
    "print(\"\\n===== Jumlah Nilai Kosong Setelah Imputasi (Cleveland) =====\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec4cfbb3-a465-4f3f-b723-4793834aa455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TAHAP 3: Encoding Fitur Kategorikal (Cleveland) =====\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== TAHAP 3: Encoding Fitur Kategorikal (Cleveland) =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e262727-fd0a-403f-8070-f695a1b69f64",
   "metadata": {},
   "source": [
    "### Kolom yang perlu di-encode: sex, cp, restecg, slope, thal\n",
    "### fbs dan exang sudah 0/1\n",
    "\n",
    "### Encoding 'sex' secara manual (Male: 1, Female: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96077539-f72e-4575-9754-0b2c85fdc00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kolom 'sex' setelah encoding:\n",
      "sex\n",
      "1    207\n",
      "0     97\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sex_map = {'Male': 1, 'Female': 0}\n",
    "df['sex'] = df['sex'].map(sex_map)\n",
    "print(\"\\nKolom 'sex' setelah encoding:\")\n",
    "print(df['sex'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea1671d-6758-4fc1-9510-3dcfb5b8fac2",
   "metadata": {},
   "source": [
    "# Encoding kolom kategorikal lainnya menggunakan pd.get_dummies()\n",
    "# Ini akan membuat kolom baru untuk setiap kategori unik dan drop kolom asli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33b862e2-23a6-4d53-a5c9-cc22aae8c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['cp', 'restecg', 'slope', 'thal']\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c127cf-1b41-48a3-805d-c4991e12dc6d",
   "metadata": {},
   "source": [
    "# drop_first=True untuk menghindari multikolinearitas, \n",
    "# satu kategori bisa direpresentasikan dengan ketiadaan kategori lain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56de93fc-1325-4296-b733-cc007b874321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 5 Baris Pertama Setelah Encoding Kategorikal =====\n",
      "   age  sex  trestbps   chol  fbs  thalch  exang  oldpeak   ca  target  \\\n",
      "0   63    1     145.0  233.0  1.0   150.0    0.0      2.3  0.0       0   \n",
      "1   67    1     160.0  286.0  0.0   108.0    1.0      1.5  3.0       1   \n",
      "2   67    1     120.0  229.0  0.0   129.0    1.0      2.6  2.0       1   \n",
      "3   37    1     130.0  250.0  0.0   187.0    0.0      3.5  0.0       0   \n",
      "4   41    0     130.0  204.0  0.0   172.0    0.0      1.4  0.0       0   \n",
      "\n",
      "   cp_atypical angina  cp_non-anginal  cp_typical angina  restecg_normal  \\\n",
      "0               False           False               True           False   \n",
      "1               False           False              False           False   \n",
      "2               False           False              False           False   \n",
      "3               False            True              False            True   \n",
      "4                True           False              False           False   \n",
      "\n",
      "   restecg_st-t abnormality  slope_flat  slope_upsloping  thal_normal  \\\n",
      "0                     False       False            False        False   \n",
      "1                     False        True            False         True   \n",
      "2                     False        True            False        False   \n",
      "3                     False       False            False         True   \n",
      "4                     False       False             True         True   \n",
      "\n",
      "   thal_reversable defect  \n",
      "0                   False  \n",
      "1                   False  \n",
      "2                    True  \n",
      "3                   False  \n",
      "4                   False  \n",
      "\n",
      "===== Kolom Setelah Encoding =====\n",
      "['age', 'sex', 'trestbps', 'chol', 'fbs', 'thalch', 'exang', 'oldpeak', 'ca', 'target', 'cp_atypical angina', 'cp_non-anginal', 'cp_typical angina', 'restecg_normal', 'restecg_st-t abnormality', 'slope_flat', 'slope_upsloping', 'thal_normal', 'thal_reversable defect']\n",
      "\n",
      "===== Informasi Dataset Setelah Encoding =====\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 304 entries, 0 to 303\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       304 non-null    int64  \n",
      " 1   sex                       304 non-null    int64  \n",
      " 2   trestbps                  304 non-null    float64\n",
      " 3   chol                      304 non-null    float64\n",
      " 4   fbs                       304 non-null    float64\n",
      " 5   thalch                    304 non-null    float64\n",
      " 6   exang                     304 non-null    float64\n",
      " 7   oldpeak                   304 non-null    float64\n",
      " 8   ca                        304 non-null    float64\n",
      " 9   target                    304 non-null    int64  \n",
      " 10  cp_atypical angina        304 non-null    bool   \n",
      " 11  cp_non-anginal            304 non-null    bool   \n",
      " 12  cp_typical angina         304 non-null    bool   \n",
      " 13  restecg_normal            304 non-null    bool   \n",
      " 14  restecg_st-t abnormality  304 non-null    bool   \n",
      " 15  slope_flat                304 non-null    bool   \n",
      " 16  slope_upsloping           304 non-null    bool   \n",
      " 17  thal_normal               304 non-null    bool   \n",
      " 18  thal_reversable defect    304 non-null    bool   \n",
      "dtypes: bool(9), float64(7), int64(3)\n",
      "memory usage: 28.8 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== 5 Baris Pertama Setelah Encoding Kategorikal =====\")\n",
    "print(df.head())\n",
    "print(\"\\n===== Kolom Setelah Encoding =====\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\n===== Informasi Dataset Setelah Encoding =====\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdbd48c-e7f4-43f0-bf04-54626f72011e",
   "metadata": {},
   "source": [
    "### ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b0c0ff7-66d7-4655-849e-c2c3c9a5a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TAHAP 4: Pemisahan Fitur dan Target, Pembagian Data =====\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle # Untuk menyimpan objek scaler\n",
    "import os\n",
    "\n",
    "print(\"\\n===== TAHAP 4: Pemisahan Fitur dan Target, Pembagian Data =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ce74f25-8614-49d1-a2b5-936823043de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TAHAP 4: Pemisahan Fitur dan Target, Pembagian Data =====\n",
      "Shape X (fitur): (304, 18)\n",
      "Shape y (target): (304,)\n",
      "\n",
      "Shape X_train: (243, 18)\n",
      "Shape X_test: (61, 18)\n",
      "Shape y_train: (243,)\n",
      "Shape y_test: (61,)\n",
      "\n",
      "Distribusi target di y_train:\n",
      "target\n",
      "0    0.54321\n",
      "1    0.45679\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribusi target di y_test:\n",
      "target\n",
      "0    0.540984\n",
      "1    0.459016\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "===== TAHAP 5: Feature Scaling =====\n",
      "\n",
      "===== 5 Baris Pertama X_train Setelah Scaling =====\n",
      "          age       sex  trestbps      chol       fbs    thalch     exang  \\\n",
      "68   0.509621  0.687552  2.220951  1.436115 -0.417029 -0.434612  1.440816   \n",
      "208  0.064161  0.687552 -0.061765  0.218713 -0.417029  0.225180 -0.694051   \n",
      "167 -0.047204 -1.454436  0.052371  0.713282  2.397916  0.401125  1.440816   \n",
      "105 -0.047204  0.687552 -1.317259  1.112742 -0.417029  0.269166 -0.694051   \n",
      "189  1.623272  0.687552  0.508914  0.066538 -0.417029 -0.170695 -0.694051   \n",
      "\n",
      "      oldpeak        ca  cp_atypical angina  cp_non-anginal  \\\n",
      "68   2.149656 -0.687622           -0.457116       -0.616994   \n",
      "208 -0.886320 -0.687622            2.187628       -0.616994   \n",
      "167 -0.886320  0.449059            2.187628       -0.616994   \n",
      "105 -0.886320 -0.687622            2.187628       -0.616994   \n",
      "189  0.899548  2.722422           -0.457116        1.620761   \n",
      "\n",
      "     cp_typical angina  restecg_normal  restecg_st-t abnormality  slope_flat  \\\n",
      "68           -0.291241       -1.029234                 -0.064282   -0.909433   \n",
      "208          -0.291241        0.971597                 -0.064282   -0.909433   \n",
      "167          -0.291241       -1.029234                 -0.064282   -0.909433   \n",
      "105          -0.291241        0.971597                 -0.064282   -0.909433   \n",
      "189          -0.291241       -1.029234                 -0.064282    1.099587   \n",
      "\n",
      "     slope_upsloping  thal_normal  thal_reversable defect  \n",
      "68         -0.963624    -1.136861                1.248157  \n",
      "208         1.037749     0.879615               -0.801182  \n",
      "167         1.037749     0.879615               -0.801182  \n",
      "105         1.037749    -1.136861                1.248157  \n",
      "189        -0.963624    -1.136861                1.248157  \n",
      "\n",
      "===== Deskripsi Statistik X_train Setelah Scaling (Mean & Std) =====\n",
      "               age           sex      trestbps          chol           fbs  \\\n",
      "mean  1.480297e-16 -9.503144e-17  4.386066e-17  1.315820e-16  6.761852e-17   \n",
      "std   1.002064e+00  1.002064e+00  1.002064e+00  1.002064e+00  1.002064e+00   \n",
      "\n",
      "            thalch         exang       oldpeak            ca  \\\n",
      "mean  1.462022e-17 -6.579099e-17 -8.772133e-17 -2.558539e-17   \n",
      "std   1.002064e+00  1.002064e+00  1.002064e+00  1.002064e+00   \n",
      "\n",
      "      cp_atypical angina  cp_non-anginal  cp_typical angina  restecg_normal  \\\n",
      "mean        2.924044e-17    5.848088e-17      -1.078241e-16    2.924044e-17   \n",
      "std         1.002064e+00    1.002064e+00       1.002064e+00    1.002064e+00   \n",
      "\n",
      "      restecg_st-t abnormality    slope_flat  slope_upsloping   thal_normal  \\\n",
      "mean              1.462022e-17  1.462022e-16     7.310110e-17  4.751572e-17   \n",
      "std               1.002064e+00  1.002064e+00     1.002064e+00  1.002064e+00   \n",
      "\n",
      "      thal_reversable defect  \n",
      "mean           -2.193033e-17  \n",
      "std             1.002064e+00  \n",
      "\n",
      "Objek Scaler disimpan di: models/heart_disease_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== TAHAP 4: Pemisahan Fitur dan Target, Pembagian Data =====\")\n",
    "\n",
    "# 1. Pisahkan Fitur (X) dan Target (y)\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "print(\"Shape X (fitur):\", X.shape)\n",
    "print(\"Shape y (target):\", y.shape)\n",
    "\n",
    "# 2. Pembagian Data menjadi Training dan Testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"\\nShape X_train:\", X_train.shape)\n",
    "print(\"Shape X_test:\", X_test.shape)\n",
    "print(\"Shape y_train:\", y_train.shape)\n",
    "print(\"Shape y_test:\", y_test.shape)\n",
    "print(\"\\nDistribusi target di y_train:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nDistribusi target di y_test:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n===== TAHAP 5: Feature Scaling =====\")\n",
    "numeric_cols = X_train.columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler HANYA pada X_train dan transform X_train\n",
    "X_train_scaled_np = scaler.fit_transform(X_train[numeric_cols]) # Hasilnya array NumPy\n",
    "\n",
    "# Transform X_test menggunakan scaler yang sudah di-fit pada X_train\n",
    "X_test_scaled_np = scaler.transform(X_test[numeric_cols]) # Hasilnya array NumPy\n",
    "\n",
    "# Konversi kembali ke DataFrame\n",
    "# Menggunakan nama variabel yang berbeda untuk hasil array NumPy agar tidak bingung\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled_np, columns=numeric_cols, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled_np, columns=numeric_cols, index=X_test.index) # PERBAIKAN DI SINI\n",
    "\n",
    "print(\"\\n===== 5 Baris Pertama X_train Setelah Scaling =====\")\n",
    "print(X_train_scaled.head())\n",
    "print(\"\\n===== Deskripsi Statistik X_train Setelah Scaling (Mean & Std) =====\")\n",
    "print(X_train_scaled.describe().loc[['mean', 'std']])\n",
    "\n",
    "# 3. Simpan Objek Scaler\n",
    "MODELS_DIR = \"models\"\n",
    "SCALER_PATH = f\"{MODELS_DIR}/heart_disease_scaler.pkl\"\n",
    "\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.makedirs(MODELS_DIR)\n",
    "\n",
    "with open(SCALER_PATH, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"\\nObjek Scaler disimpan di: {SCALER_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b7dff5-08c9-4b78-8b33-5e335bb3a5a2",
   "metadata": {},
   "source": [
    "### ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3327a8a-a154-4c90-a58f-6be2f987c395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TAHAP 6: Pelatihan dan Evaluasi Model Dasar =====\n",
      "\n",
      "--- Model: Logistic Regression ---\n",
      "Akurasi Logistic Regression: 0.8688524590163934\n",
      "Presisi Logistic Regression: 0.8333333333333334\n",
      "Recall Logistic Regression: 0.8928571428571429\n",
      "F1-Score Logistic Regression: 0.8620689655172413\n",
      "ROC-AUC Logistic Regression: 0.9437229437229437\n",
      "Confusion Matrix Logistic Regression:\n",
      " [[28  5]\n",
      " [ 3 25]]\n",
      "Classification Report Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88        33\n",
      "           1       0.83      0.89      0.86        28\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Model Logistic Regression disimpan di: models/lr_model_basic.pkl\n",
      "\n",
      "--- Model: Random Forest Classifier ---\n",
      "Akurasi Random Forest: 0.8688524590163934\n",
      "Presisi Random Forest: 0.8333333333333334\n",
      "Recall Random Forest: 0.8928571428571429\n",
      "F1-Score Random Forest: 0.8620689655172413\n",
      "ROC-AUC Random Forest: 0.9442640692640694\n",
      "Confusion Matrix Random Forest:\n",
      " [[28  5]\n",
      " [ 3 25]]\n",
      "Classification Report Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88        33\n",
      "           1       0.83      0.89      0.86        28\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "Model Random Forest disimpan di: models/rf_model_basic.pkl\n",
      "\n",
      "--- Model: Support Vector Classifier (SVC) ---\n",
      "Akurasi SVC: 0.819672131147541\n",
      "Presisi SVC: 0.8148148148148148\n",
      "Recall SVC: 0.7857142857142857\n",
      "F1-Score SVC: 0.8\n",
      "ROC-AUC SVC: 0.9231601731601731\n",
      "Confusion Matrix SVC:\n",
      " [[28  5]\n",
      " [ 6 22]]\n",
      "Classification Report SVC:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84        33\n",
      "           1       0.81      0.79      0.80        28\n",
      "\n",
      "    accuracy                           0.82        61\n",
      "   macro avg       0.82      0.82      0.82        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n",
      "Model SVC disimpan di: models/svc_model_basic.pkl\n",
      "\n",
      "--- Model: XGBoost Classifier ---\n",
      "Akurasi XGBoost: 0.8524590163934426\n",
      "Presisi XGBoost: 0.7878787878787878\n",
      "Recall XGBoost: 0.9285714285714286\n",
      "F1-Score XGBoost: 0.8524590163934426\n",
      "ROC-AUC XGBoost: 0.9372294372294372\n",
      "Confusion Matrix XGBoost:\n",
      " [[26  7]\n",
      " [ 2 26]]\n",
      "Classification Report XGBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.85        33\n",
      "           1       0.79      0.93      0.85        28\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.86      0.86      0.85        61\n",
      "weighted avg       0.86      0.85      0.85        61\n",
      "\n",
      "Model XGBoost disimpan di: models/xgb_model_basic.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasir\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\training.py:183: UserWarning: [14:32:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# Pastikan semua library yang dibutuhkan sudah di-import di bagian atas skrip Anda\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC  # <-- Tambahan untuk Support Vector Classifier\n",
    "from xgboost import XGBClassifier # <-- Tambahan untuk XGBoost\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score\n",
    "# import pickle # <-- Pastikan pickle sudah di-import\n",
    "# MODELS_DIR = 'models' # <-- Pastikan variabel ini sudah didefinisikan\n",
    "\n",
    "print(\"\\n===== TAHAP 6: Pelatihan dan Evaluasi Model Dasar =====\")\n",
    "\n",
    "# --- 1. Logistic Regression ---\n",
    "print(\"\\n--- Model: Logistic Regression ---\")\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediksi pada test set\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_prob_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluasi\n",
    "print(\"Akurasi Logistic Regression:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Presisi Logistic Regression:\", precision_score(y_test, y_pred_lr))\n",
    "print(\"Recall Logistic Regression:\", recall_score(y_test, y_pred_lr))\n",
    "print(\"F1-Score Logistic Regression:\", f1_score(y_test, y_pred_lr))\n",
    "print(\"ROC-AUC Logistic Regression:\", roc_auc_score(y_test, y_prob_lr))\n",
    "print(\"Confusion Matrix Logistic Regression:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"Classification Report Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Simpan model Logistic Regression\n",
    "LR_MODEL_PATH = f\"{MODELS_DIR}/lr_model_basic.pkl\"\n",
    "with open(LR_MODEL_PATH, 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "print(f\"Model Logistic Regression disimpan di: {LR_MODEL_PATH}\")\n",
    "\n",
    "\n",
    "# --- 2. Random Forest Classifier ---\n",
    "print(\"\\n--- Model: Random Forest Classifier ---\")\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediksi pada test set\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "y_prob_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluasi\n",
    "print(\"Akurasi Random Forest:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Presisi Random Forest:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall Random Forest:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1-Score Random Forest:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"ROC-AUC Random Forest:\", roc_auc_score(y_test, y_prob_rf))\n",
    "print(\"Confusion Matrix Random Forest:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Classification Report Random Forest:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Simpan model Random Forest\n",
    "RF_MODEL_PATH = f\"{MODELS_DIR}/rf_model_basic.pkl\"\n",
    "with open(RF_MODEL_PATH, 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "print(f\"Model Random Forest disimpan di: {RF_MODEL_PATH}\")\n",
    "\n",
    "\n",
    "# --- 3. Support Vector Classifier (SVC) --- (BARU)\n",
    "print(\"\\n--- Model: Support Vector Classifier (SVC) ---\")\n",
    "# probability=True diperlukan untuk menghitung ROC-AUC score\n",
    "svc_model = SVC(random_state=42, probability=True) \n",
    "svc_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediksi pada test set\n",
    "y_pred_svc = svc_model.predict(X_test_scaled)\n",
    "y_prob_svc = svc_model.predict_proba(X_test_scaled)[:, 1] # Probabilitas untuk kelas positif (1)\n",
    "\n",
    "# Evaluasi\n",
    "print(\"Akurasi SVC:\", accuracy_score(y_test, y_pred_svc))\n",
    "print(\"Presisi SVC:\", precision_score(y_test, y_pred_svc))\n",
    "print(\"Recall SVC:\", recall_score(y_test, y_pred_svc))\n",
    "print(\"F1-Score SVC:\", f1_score(y_test, y_pred_svc))\n",
    "print(\"ROC-AUC SVC:\", roc_auc_score(y_test, y_prob_svc))\n",
    "print(\"Confusion Matrix SVC:\\n\", confusion_matrix(y_test, y_pred_svc))\n",
    "print(\"Classification Report SVC:\\n\", classification_report(y_test, y_pred_svc))\n",
    "\n",
    "# Simpan model SVC\n",
    "SVC_MODEL_PATH = f\"{MODELS_DIR}/svc_model_basic.pkl\"\n",
    "with open(SVC_MODEL_PATH, 'wb') as f:\n",
    "    pickle.dump(svc_model, f)\n",
    "print(f\"Model SVC disimpan di: {SVC_MODEL_PATH}\")\n",
    "\n",
    "\n",
    "# --- 4. XGBoost Classifier --- (BARU)\n",
    "print(\"\\n--- Model: XGBoost Classifier ---\")\n",
    "# use_label_encoder=False untuk menghindari deprecation warning\n",
    "# eval_metric='logloss' adalah metrik evaluasi yang umum untuk klasifikasi biner\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediksi pada test set\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "y_prob_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1] # Probabilitas untuk kelas positif (1)\n",
    "\n",
    "# Evaluasi\n",
    "print(\"Akurasi XGBoost:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Presisi XGBoost:\", precision_score(y_test, y_pred_xgb))\n",
    "print(\"Recall XGBoost:\", recall_score(y_test, y_pred_xgb))\n",
    "print(\"F1-Score XGBoost:\", f1_score(y_test, y_pred_xgb))\n",
    "print(\"ROC-AUC XGBoost:\", roc_auc_score(y_test, y_prob_xgb))\n",
    "print(\"Confusion Matrix XGBoost:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"Classification Report XGBoost:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# Simpan model XGBoost\n",
    "XGB_MODEL_PATH = f\"{MODELS_DIR}/xgb_model_basic.pkl\"\n",
    "with open(XGB_MODEL_PATH, 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "print(f\"Model XGBoost disimpan di: {XGB_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53dd182-239b-495b-b90e-a8bb89d94c0c",
   "metadata": {},
   "source": [
    "### ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3762640-2eb0-457a-ac80-9b25370109ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TAHAP 7: Optimasi Hyperparameter =====\n",
      "\n",
      "--- Optimasi: Logistic Regression ---\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Parameter terbaik untuk Logistic Regression: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Skor ROC-AUC terbaik (cross-val): 0.9020365302973998\n",
      "\n",
      "--- Hasil Logistic Regression Setelah Optimasi ---\n",
      "ROC-AUC: 0.9512987012987013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89        33\n",
      "           1       0.86      0.89      0.88        28\n",
      "\n",
      "    accuracy                           0.89        61\n",
      "   macro avg       0.88      0.89      0.88        61\n",
      "weighted avg       0.89      0.89      0.89        61\n",
      "\n",
      "Model Logistic Regression (Optimized) disimpan di: models/lr_model_optimized.pkl\n",
      "\n",
      "--- Optimasi: Random Forest Classifier ---\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Parameter terbaik untuk Random Forest: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Skor ROC-AUC terbaik (cross-val): 0.8990253707645012\n",
      "\n",
      "--- Hasil Random Forest Setelah Optimasi ---\n",
      "ROC-AUC: 0.9383116883116883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83        33\n",
      "           1       0.77      0.86      0.81        28\n",
      "\n",
      "    accuracy                           0.82        61\n",
      "   macro avg       0.82      0.82      0.82        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n",
      "Model Random Forest (Optimized) disimpan di: models/rf_model_optimized.pkl\n",
      "\n",
      "--- Optimasi: Support Vector Classifier (SVC) ---\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Parameter terbaik untuk SVC: {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Skor ROC-AUC terbaik (cross-val): 0.8959905633818677\n",
      "\n",
      "--- Hasil SVC Setelah Optimasi ---\n",
      "ROC-AUC: 0.9361471861471861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86        33\n",
      "           1       0.91      0.71      0.80        28\n",
      "\n",
      "    accuracy                           0.84        61\n",
      "   macro avg       0.85      0.83      0.83        61\n",
      "weighted avg       0.85      0.84      0.83        61\n",
      "\n",
      "Model SVC (Optimized) disimpan di: models/svc_model_optimized.pkl\n",
      "\n",
      "--- Optimasi: XGBoost Classifier ---\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Parameter terbaik untuk XGBoost: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
      "Skor ROC-AUC terbaik (cross-val): 0.8972731777079603\n",
      "\n",
      "--- Hasil XGBoost Setelah Optimasi ---\n",
      "ROC-AUC: 0.9512987012987013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.85        33\n",
      "           1       0.79      0.93      0.85        28\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.86      0.86      0.85        61\n",
      "weighted avg       0.86      0.85      0.85        61\n",
      "\n",
      "Model XGBoost (Optimized) disimpan di: models/xgb_model_optimized.pkl\n",
      "\n",
      "===== Pelatihan dan Optimasi Selesai =====\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"\\n===== TAHAP 7: Optimasi Hyperparameter =====\")\n",
    "\n",
    "# --- 1. Optimasi Hyperparameter untuk Logistic Regression ---\n",
    "print(\"\\n--- Optimasi: Logistic Regression ---\")\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "grid_lr = GridSearchCV(LogisticRegression(random_state=42, max_iter=2000),\n",
    "                       param_grid_lr, cv=5, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "grid_lr.fit(X_train_scaled, y_train)\n",
    "best_lr_model = grid_lr.best_estimator_\n",
    "\n",
    "print(\"Parameter terbaik untuk Logistic Regression:\", grid_lr.best_params_)\n",
    "print(\"Skor ROC-AUC terbaik (cross-val):\", grid_lr.best_score_)\n",
    "\n",
    "# Evaluasi pada test set\n",
    "y_pred_lr_optimized = best_lr_model.predict(X_test_scaled)\n",
    "y_prob_lr_optimized = best_lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\n--- Hasil Logistic Regression Setelah Optimasi ---\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_lr_optimized))\n",
    "print(classification_report(y_test, y_pred_lr_optimized))\n",
    "LR_OPTIMIZED_MODEL_PATH = f\"{MODELS_DIR}/lr_model_optimized.pkl\"\n",
    "with open(LR_OPTIMIZED_MODEL_PATH, 'wb') as f:\n",
    "    pickle.dump(best_lr_model, f)\n",
    "print(f\"Model Logistic Regression (Optimized) disimpan di: {LR_OPTIMIZED_MODEL_PATH}\")\n",
    "\n",
    "# --- 2. Optimasi Hyperparameter untuk Random Forest ---\n",
    "print(\"\\n--- Optimasi: Random Forest Classifier ---\")\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                       param_grid_rf, cv=5, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "grid_rf.fit(X_train_scaled, y_train)\n",
    "best_rf_model = grid_rf.best_estimator_\n",
    "\n",
    "print(\"Parameter terbaik untuk Random Forest:\", grid_rf.best_params_)\n",
    "print(\"Skor ROC-AUC terbaik (cross-val):\", grid_rf.best_score_)\n",
    "\n",
    "# Evaluasi pada test set\n",
    "y_pred_rf_optimized = best_rf_model.predict(X_test_scaled)\n",
    "y_prob_rf_optimized = best_rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\n--- Hasil Random Forest Setelah Optimasi ---\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_rf_optimized))\n",
    "print(classification_report(y_test, y_pred_rf_optimized))\n",
    "RF_OPTIMIZED_MODEL_PATH = f\"{MODELS_DIR}/rf_model_optimized.pkl\"\n",
    "with open(RF_OPTIMIZED_MODEL_PATH, 'wb') as f:\n",
    "    pickle.dump(best_rf_model, f)\n",
    "print(f\"Model Random Forest (Optimized) disimpan di: {RF_OPTIMIZED_MODEL_PATH}\")\n",
    "\n",
    "# --- 3. Optimasi Hyperparameter untuk SVC --- (BARU)\n",
    "print(\"\\n--- Optimasi: Support Vector Classifier (SVC) ---\")\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "grid_svc = GridSearchCV(SVC(random_state=42, probability=True),\n",
    "                        param_grid_svc, cv=5, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "grid_svc.fit(X_train_scaled, y_train)\n",
    "best_svc_model = grid_svc.best_estimator_\n",
    "\n",
    "print(\"Parameter terbaik untuk SVC:\", grid_svc.best_params_)\n",
    "print(\"Skor ROC-AUC terbaik (cross-val):\", grid_svc.best_score_)\n",
    "\n",
    "# Evaluasi pada test set\n",
    "y_pred_svc_optimized = best_svc_model.predict(X_test_scaled)\n",
    "y_prob_svc_optimized = best_svc_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\n--- Hasil SVC Setelah Optimasi ---\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_svc_optimized))\n",
    "print(classification_report(y_test, y_pred_svc_optimized))\n",
    "SVC_OPTIMIZED_MODEL_PATH = f\"{MODELS_DIR}/svc_model_optimized.pkl\"\n",
    "with open(SVC_OPTIMIZED_MODEL_PATH, 'wb') as f:\n",
    "    pickle.dump(best_svc_model, f)\n",
    "print(f\"Model SVC (Optimized) disimpan di: {SVC_OPTIMIZED_MODEL_PATH}\")\n",
    "\n",
    "# --- 4. Optimasi Hyperparameter untuk XGBoost --- (BARU)\n",
    "print(\"\\n--- Optimasi: XGBoost Classifier ---\")\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "grid_xgb = GridSearchCV(XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "                        param_grid_xgb, cv=5, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "grid_xgb.fit(X_train_scaled, y_train)\n",
    "best_xgb_model = grid_xgb.best_estimator_\n",
    "\n",
    "print(\"Parameter terbaik untuk XGBoost:\", grid_xgb.best_params_)\n",
    "print(\"Skor ROC-AUC terbaik (cross-val):\", grid_xgb.best_score_)\n",
    "\n",
    "# Evaluasi pada test set\n",
    "y_pred_xgb_optimized = best_xgb_model.predict(X_test_scaled)\n",
    "y_prob_xgb_optimized = best_xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\n--- Hasil XGBoost Setelah Optimasi ---\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_xgb_optimized))\n",
    "print(classification_report(y_test, y_pred_xgb_optimized))\n",
    "XGB_OPTIMIZED_MODEL_PATH = f\"{MODELS_DIR}/xgb_model_optimized.pkl\"\n",
    "with open(XGB_OPTIMIZED_MODEL_PATH, 'wb') as f:\n",
    "    pickle.dump(best_xgb_model, f)\n",
    "print(f\"Model XGBoost (Optimized) disimpan di: {XGB_OPTIMIZED_MODEL_PATH}\")\n",
    "\n",
    "print(\"\\n===== Pelatihan dan Optimasi Selesai =====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f018b0-41b0-4c45-bc60-1d2a3a1b73b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
