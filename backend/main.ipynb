{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d60157-acfc-40fa-b19b-fc5e18f2b58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 0.0/95.2 kB ? eta -:--:--\n",
      "     ------------------------- -------------- 61.4/95.2 kB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 95.2/95.2 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting starlette<0.47.0,>=0.40.0\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "     ---------------------------------------- 0.0/72.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 72.0/72.0 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "     ---------------------------------------- 0.0/444.2 kB ? eta -:--:--\n",
      "     -------- ------------------------------ 92.2/444.2 kB 2.6 MB/s eta 0:00:01\n",
      "     -------------- ----------------------- 174.1/444.2 kB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------- --------------- 266.2/444.2 kB 2.3 MB/s eta 0:00:01\n",
      "     ------------------------------- ------ 368.6/444.2 kB 2.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 444.2/444.2 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\richa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from fastapi) (4.13.2)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.1/2.0 MB 2.8 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 0.3/2.0 MB 3.0 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 0.4/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 0.6/2.0 MB 3.2 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 0.7/2.0 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 0.9/2.0 MB 3.1 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.0/2.0 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.2/2.0 MB 3.3 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.3/2.0 MB 3.3 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.5/2.0 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.5/2.0 MB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.6/2.0 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.7/2.0 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 1.8/2.0 MB 2.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.9/2.0 MB 2.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.0/2.0 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\richa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\richa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\richa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\richa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.0)\n",
      "Installing collected packages: typing-inspection, pydantic-core, annotated-types, pydantic, starlette, fastapi\n",
      "Successfully installed annotated-types-0.7.0 fastapi-0.115.12 pydantic-2.11.5 pydantic-core-2.33.2 starlette-0.46.2 typing-inspection-0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script fastapi.exe is installed in 'C:\\Users\\Richa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Richa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68209b84-e44d-4a80-91a2-b3bac1a27303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil dimuat dari: models/lr_model_optimized.pkl\n",
      "Scaler berhasil dimuat dari: models/heart_disease_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel, Field # Untuk validasi data input\n",
    "from typing import Literal # Untuk tipe data literal seperti 'Male'/'Female'\n",
    "\n",
    "# === PATH KONFIGURASI (Sesuaikan jika struktur foldermu berbeda) ===\n",
    "MODELS_DIR = \"models\"\n",
    "SCALER_PATH = f\"{MODELS_DIR}/heart_disease_scaler.pkl\"\n",
    "MODEL_PATH = f\"{MODELS_DIR}/lr_model_optimized.pkl\" # Kita pakai model LR Optimized\n",
    "\n",
    "# === INISIALISASI APLIKASI FastAPI ===\n",
    "app = FastAPI(title=\"API Prediksi Penyakit Jantung\",\n",
    "              description=\"API untuk memprediksi risiko penyakit jantung menggunakan model Logistic Regression.\",\n",
    "              version=\"0.1.0\")\n",
    "\n",
    "# === MUAT MODEL DAN SCALER SAAT APLIKASI DIMULAI ===\n",
    "# Ini akan dimuat sekali saat server FastAPI pertama kali dijalankan\n",
    "try:\n",
    "    with open(MODEL_PATH, 'rb') as f_model:\n",
    "        model = pickle.load(f_model)\n",
    "    print(f\"Model berhasil dimuat dari: {MODEL_PATH}\")\n",
    "\n",
    "    with open(SCALER_PATH, 'rb') as f_scaler:\n",
    "        scaler = pickle.load(f_scaler)\n",
    "    print(f\"Scaler berhasil dimuat dari: {SCALER_PATH}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error saat memuat file model/scaler: {e}\")\n",
    "    print(\"Pastikan script train_model.py sudah dijalankan dan file .pkl ada di folder 'models'.\")\n",
    "    model = None\n",
    "    scaler = None\n",
    "except Exception as e:\n",
    "    print(f\"Terjadi error lain saat memuat file: {e}\")\n",
    "    model = None\n",
    "    scaler = None\n",
    "\n",
    "# === DEFINISIKAN MODEL INPUT (REQUEST BODY) MENGGUNAKAN PYDANTIC ===\n",
    "# Ini adalah fitur-fitur SEBELUM pra-pemrosesan (encoding dan scaling)\n",
    "# Nama field harus sesuai dengan apa yang diharapkan frontend\n",
    "# Kita pakai nilai contoh dari dataset Cleveland dan deskripsinya\n",
    "class HeartDiseaseInput(BaseModel):\n",
    "    age: int = Field(..., example=52, description=\"Umur pasien (tahun)\")\n",
    "    sex: Literal['Male', 'Female'] = Field(..., example='Male', description=\"Jenis kelamin pasien\")\n",
    "    cp: Literal['typical angina', 'atypical angina', 'non-anginal', 'asymptomatic'] = Field(..., example='asymptomatic', description=\"Tipe nyeri dada\")\n",
    "    trestbps: float = Field(..., example=120, description=\"Tekanan darah istirahat (mm Hg)\")\n",
    "    chol: float = Field(..., example=215, description=\"Kolesterol serum (mg/dl)\")\n",
    "    fbs: bool = Field(..., example=False, description=\"Gula darah puasa > 120 mg/dl (True/False)\")\n",
    "    restecg: Literal['normal', 'st-t abnormality', 'lv hypertrophy'] = Field(..., example='normal', description=\"Hasil elektrokardiografi istirahat\")\n",
    "    thalch: float = Field(..., example=150, description=\"Detak jantung maksimum tercapai\")\n",
    "    exang: bool = Field(..., example=False, description=\"Angina akibat olahraga (True/False)\")\n",
    "    oldpeak: float = Field(..., example=1.0, description=\"Depresi ST akibat olahraga relatif terhadap istirahat\")\n",
    "    slope: Literal['upsloping', 'flat', 'downsloping'] = Field(..., example='upsloping', description=\"Kemiringan segmen ST puncak olahraga\")\n",
    "    ca: float = Field(..., example=0.0, description=\"Jumlah pembuluh darah besar (0-3) yang diwarnai oleh fluoroskopi\") # Dulu int, tapi karena ada NaN, jadi float. Di sini kita asumsikan inputnya sudah bersih\n",
    "    thal: Literal['normal', 'fixed defect', 'reversable defect'] = Field(..., example='normal', description=\"Kelainan darah Thalassemia\")\n",
    "\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"age\": 63, \"sex\": \"Male\", \"cp\": \"typical angina\", \"trestbps\": 145.0, \"chol\": 233.0,\n",
    "                \"fbs\": True, \"restecg\": \"lv hypertrophy\", \"thalch\": 150.0, \"exang\": False,\n",
    "                \"oldpeak\": 2.3, \"slope\": \"downsloping\", \"ca\": 0.0, \"thal\": \"fixed defect\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "# === DAFTAR KOLOM YANG DIHARAPKAN MODEL SETELAH ENCODING ===\n",
    "# Ini HARUS SAMA PERSIS dengan urutan kolom X_train saat melatih model dan scaler\n",
    "# Ambil dari output X_train_scaled.columns.tolist() di train_model.py\n",
    "# Sesuaikan dengan nama kolom dummy yang benar dari proses get_dummies kamu\n",
    "EXPECTED_COLUMNS_AFTER_DUMMIES = [\n",
    "    'age', 'sex', 'trestbps', 'chol', 'fbs', 'thalch', 'exang', 'oldpeak', 'ca',\n",
    "    'cp_atypical angina', 'cp_non-anginal', 'cp_typical angina', # cp_asymptomatic adalah drop_first=True\n",
    "    'restecg_normal', 'restecg_st-t abnormality', # restecg_lv hypertrophy adalah drop_first=True (jika itu urutan pertama) atau perlu dicek lagi urutan kategori saat get_dummies\n",
    "    'slope_flat', 'slope_upsloping', # slope_downsloping adalah drop_first=True\n",
    "    'thal_normal', 'thal_reversable defect' # thal_fixed defect adalah drop_first=True\n",
    "]\n",
    "# PENTING: Verifikasi ulang nama kolom dummy ini berdasarkan output df.columns.tolist()\n",
    "# setelah pd.get_dummies(..., drop_first=True) di train_model.py mu!\n",
    "\n",
    "# === ENDPOINT PREDIKSI ===\n",
    "@app.post(\"/predict/\")\n",
    "async def predict_heart_disease(data_input: HeartDiseaseInput):\n",
    "    if not model or not scaler:\n",
    "        return {\"error\": \"Model atau scaler tidak berhasil dimuat. Cek log server.\"}\n",
    "\n",
    "    try:\n",
    "        # 1. Ubah data input Pydantic menjadi dictionary\n",
    "        input_dict = data_input.dict()\n",
    "\n",
    "        # 2. Buat DataFrame dari input_dict (hanya satu baris)\n",
    "        input_df_raw = pd.DataFrame([input_dict])\n",
    "\n",
    "        # 3. Lakukan pra-pemrosesan SAMA PERSIS seperti saat training:\n",
    "        #    a. Mapping 'sex'\n",
    "        input_df_processed = input_df_raw.copy()\n",
    "        input_df_processed['sex'] = input_df_processed['sex'].map({'Male': 1, 'Female': 0})\n",
    "        #    b. Mapping 'fbs' dan 'exang' (boolean ke int 0/1)\n",
    "        input_df_processed['fbs'] = input_df_processed['fbs'].astype(int)\n",
    "        input_df_processed['exang'] = input_df_processed['exang'].astype(int)\n",
    "\n",
    "        #    c. One-Hot Encoding untuk kolom kategorikal\n",
    "        #       PENTING: Harus menghasilkan kolom yang sama persis dengan saat training\n",
    "        #       Kita gunakan pd.get_dummies dan reindex untuk memastikan konsistensi\n",
    "        categorical_cols_api = ['cp', 'restecg', 'slope', 'thal']\n",
    "        input_df_processed = pd.get_dummies(input_df_processed, columns=categorical_cols_api, drop_first=True)\n",
    "        \n",
    "        # Reindex untuk memastikan semua kolom yang diharapkan model ada,\n",
    "        # dan urutannya benar. Kolom yang tidak ada di input_df_processed\n",
    "        # setelah get_dummies (karena inputnya hanya satu kategori) akan diisi 0.\n",
    "        input_df_final_features = input_df_processed.reindex(columns=EXPECTED_COLUMNS_AFTER_DUMMIES, fill_value=0)\n",
    "        \n",
    "        #    d. Scaling fitur menggunakan scaler yang sudah di-fit\n",
    "        #       Scaler di-fit pada semua kolom fitur (setelah encoding) saat training\n",
    "        scaled_features_np = scaler.transform(input_df_final_features)\n",
    "        #       Jika ingin tetap DataFrame (opsional, tapi baik untuk verifikasi nama fitur oleh model):\n",
    "        #       scaled_features_df = pd.DataFrame(scaled_features_np, columns=EXPECTED_COLUMNS_AFTER_DUMMIES)\n",
    "\n",
    "        # 4. Lakukan prediksi\n",
    "        prediction_proba = model.predict_proba(scaled_features_np) # Atau scaled_features_df jika dikonversi\n",
    "        prediction = model.predict(scaled_features_np)      # Atau scaled_features_df jika dikonversi\n",
    "\n",
    "        probability_class_1 = float(prediction_proba[0][1]) # Probabilitas kelas 1 (sakit)\n",
    "        predicted_class = int(prediction[0])                # Hasil kelas 0 atau 1\n",
    "\n",
    "        return {\n",
    "            \"prediction_label\": \"Risiko Penyakit Jantung\" if predicted_class == 1 else \"Risiko Rendah\",\n",
    "            \"predicted_class\": predicted_class,\n",
    "            \"probability_score_class_1\": probability_class_1,\n",
    "            \"detail_input\": input_dict # Mengembalikan input untuk verifikasi\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Terjadi kesalahan saat prediksi: {str(e)}\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
