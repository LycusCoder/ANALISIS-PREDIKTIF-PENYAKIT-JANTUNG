{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18dba819-4c74-45b8-8cd8-17dbb6718b3d",
   "metadata": {},
   "source": [
    "# Proses Pemilihan Model dan Evaluasi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38b7f726-ba27-4c3d-8ecf-2994bf93c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os # Pastikan ini diimpor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # Pastikan ini diimpor jika belum dari train_model.py\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report, roc_auc_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82fff052-3633-4bb3-b5d7-43fc231da1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TAHAP 1: MEMUAT DAN MEMPROSES ULANG DATASET (UNTUK KONSISTENSI TEST SET) =====\n"
     ]
    }
   ],
   "source": [
    "# Import model-modelnya juga jika belum\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# === PATH KONFIGURASI ===\n",
    "# Asumsi script ini dijalankan dari dalam folder 'backend'\n",
    "# atau sesuaikan path jika dijalankan dari root projek\n",
    "DATASET_PATH = \"data/heart_disease_uci.csv\"\n",
    "MODELS_DIR = \"models\" # Folder 'models' ada di dalam 'backend'\n",
    "SCALER_PATH = f\"{MODELS_DIR}/heart_disease_scaler.pkl\"\n",
    "LR_OPTIMIZED_MODEL_PATH = f\"{MODELS_DIR}/lr_model_optimized.pkl\"\n",
    "RF_OPTIMIZED_MODEL_PATH = f\"{MODELS_DIR}/rf_model_optimized.pkl\"\n",
    "\n",
    "print(\"===== TAHAP 1: MEMUAT DAN MEMPROSES ULANG DATASET (UNTUK KONSISTENSI TEST SET) =====\")\n",
    "try:\n",
    "    df_raw = pd.read_csv(DATASET_PATH, na_values=[\"?\"])\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File dataset tidak ditemukan di {DATASET_PATH}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbaf70fd-0dcf-46d0-926c-38c0d5795beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data setelah filter 'Cleveland': 304\n"
     ]
    }
   ],
   "source": [
    "# 1. Filter dataset 'Cleveland'\n",
    "df = df_raw[df_raw[\"dataset\"] == \"Cleveland\"].copy() # .copy() penting\n",
    "print(f\"Jumlah data setelah filter 'Cleveland': {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4913d85a-a50e-47c1-b0f3-81e57bbd8d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Drop kolom yang tidak relevan\n",
    "columns_to_drop = ['id', 'dataset']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30891a48-5835-48e5-91df-775c0850f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Konversi target 'num' menjadi biner\n",
    "df[\"target\"] = df[\"num\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "df.drop(columns=[\"num\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53700c3c-56ba-46e6-b766-0c8ca3d65f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Konversi boolean (fbs, exang)\n",
    "bool_map = {True: 1, False: 0, np.nan: np.nan}\n",
    "df['fbs'] = df['fbs'].map(bool_map)\n",
    "df['exang'] = df['exang'].map(bool_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c5693a9-dd12-44fa-bf34-080e046c8d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputasi missing values...\n",
      "Kolom 'slope' diimputasi dengan modus: upsloping\n",
      "Kolom 'ca' diimputasi dengan modus: 0.0\n",
      "Kolom 'thal' diimputasi dengan modus: normal\n",
      "Jumlah missing values setelah imputasi:\n",
      " age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalch      0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5. Imputasi nilai hilang (menggunakan assignment langsung, bukan inplace=True pada slice)\n",
    "print(\"\\nImputasi missing values...\")\n",
    "for col in [\"slope\", \"ca\", \"thal\"]:\n",
    "    if df[col].isnull().any():\n",
    "        mode_val = df[col].mode()[0]\n",
    "        df[col] = df[col].fillna(mode_val) # REVISI: Tidak pakai inplace=True\n",
    "        print(f\"Kolom '{col}' diimputasi dengan modus: {mode_val}\")\n",
    "print(\"Jumlah missing values setelah imputasi:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8216b3e5-e10c-4dfd-ac19-4a90c81ed584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jumlah kolom setelah get_dummies: 19\n"
     ]
    }
   ],
   "source": [
    "# 6. Encoding Fitur Kategorikal\n",
    "df[\"sex\"] = df[\"sex\"].map({\"Male\": 1, \"Female\": 0})\n",
    "categorical_cols = [\"cp\", \"restecg\", \"slope\", \"thal\"]\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "print(f\"\\nJumlah kolom setelah get_dummies: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0814758d-e59e-4d89-95da-01bce3c3cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Pisahkan Fitur (X) dan Target (y)\n",
    "# Pastikan kolom 'target' ada sebelum di-drop\n",
    "if 'target' not in df.columns:\n",
    "    print(\"Error: Kolom 'target' tidak ditemukan setelah pra-pemrosesan.\")\n",
    "    exit()\n",
    "\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd5d40d1-7942-44ed-8ed0-51e94a16645f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape X_test_original: (61, 18), Shape y_test: (61,)\n"
     ]
    }
   ],
   "source": [
    "# 8. Split data untuk mendapatkan X_test_original dan y_test yang konsisten\n",
    "# Variabel X_train_original dan y_train_original sengaja diberi nama beda\n",
    "# karena kita tidak akan melatih ulang scaler di sini, hanya menggunakan X_test_original.\n",
    "_, X_test_original, _, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"\\nShape X_test_original: {X_test_original.shape}, Shape y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3273282-b463-47c7-bab6-faaf6c8e601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memuat scaler dan model...\n",
      "Scaler dan model berhasil dimuat.\n"
     ]
    }
   ],
   "source": [
    "# === TAHAP 2: MUAT SCALER DAN MODEL YANG SUDAH DILATIH ===\n",
    "print(\"\\nMemuat scaler dan model...\")\n",
    "try:\n",
    "    with open(SCALER_PATH, \"rb\") as f:\n",
    "        scaler = pickle.load(f)\n",
    "    with open(LR_OPTIMIZED_MODEL_PATH, \"rb\") as f:\n",
    "        lr_optimized_model = pickle.load(f)\n",
    "    with open(RF_OPTIMIZED_MODEL_PATH, \"rb\") as f:\n",
    "        rf_optimized_model = pickle.load(f)\n",
    "    print(\"Scaler dan model berhasil dimuat.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error saat memuat file model/scaler: {e}\")\n",
    "    print(\"Pastikan script train_model.py sudah dijalankan dan file .pkl ada di folder 'models'.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Terjadi error lain saat memuat file: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60ea38f3-00dc-48d9-a0be-a24eaa06e8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape X_test_scaled_df (setelah scaling dan jadi DataFrame): (61, 18)\n"
     ]
    }
   ],
   "source": [
    "# === TAHAP 3: TRANSFORMASI (SCALING) TEST SET ===\n",
    "# Pastikan kolom X_test_original SAMA PERSIS dengan yang digunakan saat scaler di-fit\n",
    "# Cara paling aman adalah menyimpan daftar kolom dari X_train saat scaler di-fit (di train_model.py)\n",
    "# dan menggunakannya di sini untuk memastikan konsistensi.\n",
    "# Untuk saat ini, kita asumsikan kolomnya sudah benar karena proses preprocessingnya identik.\n",
    "\n",
    "# Dapatkan nama kolom dari X_test_original (atau dari X_train yang dipakai untuk fit scaler)\n",
    "# Ini penting agar DataFrame hasil scaling punya nama kolom yang benar\n",
    "feature_names = X_test_original.columns\n",
    "\n",
    "try:\n",
    "    X_test_scaled_np = scaler.transform(X_test_original)\n",
    "except ValueError as e:\n",
    "    print(f\"Error saat transform X_test_original: {e}\")\n",
    "    print(\"Kemungkinan jumlah atau urutan fitur tidak cocok dengan saat scaler di-fit.\")\n",
    "    print(f\"Fitur saat scaler di-fit (dari scaler.feature_names_in_ jika tersedia): {getattr(scaler, 'feature_names_in_', 'Tidak tersedia')}\")\n",
    "    print(f\"Fitur di X_test_original: {X_test_original.columns.tolist()}\")\n",
    "    exit()\n",
    "\n",
    "# KONVERSI KEMBALI KE DATAFRAME DENGAN NAMA KOLOM YANG BENAR\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled_np, columns=feature_names, index=X_test_original.index)\n",
    "print(f\"\\nShape X_test_scaled_df (setelah scaling dan jadi DataFrame): {X_test_scaled_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "143ac00a-8504-4d1d-ab3c-f57e8e3b8217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== HASIL EVALUASI MODEL PADA TEST SET =====\n",
      "\n",
      "--- Model: Logistic Regression Optimized ---\n",
      "Akurasi: 0.8852\n",
      "Presisi: 0.8621\n",
      "Recall: 0.8929\n",
      "F1-Score: 0.8772\n",
      "ROC-AUC: 0.9513\n",
      "Confusion Matrix:\n",
      " [[29  4]\n",
      " [ 3 25]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89        33\n",
      "           1       0.86      0.89      0.88        28\n",
      "\n",
      "    accuracy                           0.89        61\n",
      "   macro avg       0.88      0.89      0.88        61\n",
      "weighted avg       0.89      0.89      0.89        61\n",
      "\n",
      "\n",
      "--- Model: Random Forest Optimized ---\n",
      "Akurasi: 0.8197\n",
      "Presisi: 0.7742\n",
      "Recall: 0.8571\n",
      "F1-Score: 0.8136\n",
      "ROC-AUC: 0.9383\n",
      "Confusion Matrix:\n",
      " [[26  7]\n",
      " [ 4 24]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83        33\n",
      "           1       0.77      0.86      0.81        28\n",
      "\n",
      "    accuracy                           0.82        61\n",
      "   macro avg       0.82      0.82      0.82        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n",
      "\n",
      "===== PEMILIHAN MODEL TERBAIK =====\n",
      "\n",
      "Logistic Regression Optimized: ROC-AUC = 0.9513\n",
      "\n",
      "Random Forest Optimized: ROC-AUC = 0.9383\n",
      "\n",
      "Model terbaik berdasarkan ROC-AUC adalah: Logistic Regression Optimized (ROC-AUC: 0.9513)\n"
     ]
    }
   ],
   "source": [
    "# === TAHAP 4: EVALUASI MODEL ===\n",
    "models_to_evaluate = {\n",
    "    \"Logistic Regression Optimized\": lr_optimized_model,\n",
    "    \"Random Forest Optimized\": rf_optimized_model\n",
    "}\n",
    "\n",
    "results_summary = {} # Ganti nama variabel 'results' agar tidak konflik jika 'results' nama kolom\n",
    "\n",
    "print(\"\\n===== HASIL EVALUASI MODEL PADA TEST SET =====\")\n",
    "for model_name, model_object in models_to_evaluate.items():\n",
    "    print(f\"\\n--- Model: {model_name} ---\")\n",
    "\n",
    "    # Gunakan DataFrame X_test_scaled_df yang sudah punya nama fitur\n",
    "    y_pred = model_object.predict(X_test_scaled_df)\n",
    "    y_prob = model_object.predict_proba(X_test_scaled_df)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results_summary[model_name] = { # Ganti nama variabel\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1,\n",
    "        \"ROC-AUC\": roc_auc,\n",
    "        \"Confusion Matrix\": cm\n",
    "    }\n",
    "\n",
    "    print(f\"Akurasi: {accuracy:.4f}\")\n",
    "    print(f\"Presisi: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# === TAHAP 5: PEMILIHAN MODEL TERBAIK BERDASARKAN ROC-AUC ===\n",
    "print(\"\\n===== PEMILIHAN MODEL TERBAIK =====\")\n",
    "# Cari nama model dengan ROC-AUC tertinggi dari dictionary results_summary\n",
    "best_model_name = None\n",
    "best_roc_auc = 0\n",
    "\n",
    "if results_summary: # Pastikan dictionary tidak kosong\n",
    "    for name, metrics in results_summary.items():\n",
    "        print(f\"\\n{name}: ROC-AUC = {metrics['ROC-AUC']:.4f}\")\n",
    "        if metrics['ROC-AUC'] > best_roc_auc:\n",
    "            best_roc_auc = metrics['ROC-AUC']\n",
    "            best_model_name = name\n",
    "    \n",
    "    if best_model_name:\n",
    "        print(f\"\\nModel terbaik berdasarkan ROC-AUC adalah: {best_model_name} (ROC-AUC: {best_roc_auc:.4f})\")\n",
    "    else:\n",
    "        print(\"Tidak dapat menentukan model terbaik dari hasil evaluasi.\")\n",
    "else:\n",
    "    print(\"Tidak ada hasil model yang dievaluasi.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
