{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68209b84-e44d-4a80-91a2-b3bac1a27303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel, Field # Untuk validasi data input\n",
    "from typing import Literal # Untuk tipe data literal seperti 'Male'/'Female'\n",
    "\n",
    "# === PATH KONFIGURASI (Sesuaikan jika struktur foldermu berbeda) ===\n",
    "MODELS_DIR = \"models\"\n",
    "SCALER_PATH = f\"{MODELS_DIR}/heart_disease_scaler.pkl\"\n",
    "MODEL_PATH = f\"{MODELS_DIR}/lr_model_optimized.pkl\" # Kita pakai model LR Optimized\n",
    "\n",
    "# === INISIALISASI APLIKASI FastAPI ===\n",
    "app = FastAPI(title=\"API Prediksi Penyakit Jantung\",\n",
    "              description=\"API untuk memprediksi risiko penyakit jantung menggunakan model Logistic Regression.\",\n",
    "              version=\"0.1.0\")\n",
    "\n",
    "# === MUAT MODEL DAN SCALER SAAT APLIKASI DIMULAI ===\n",
    "# Ini akan dimuat sekali saat server FastAPI pertama kali dijalankan\n",
    "try:\n",
    "    with open(MODEL_PATH, 'rb') as f_model:\n",
    "        model = pickle.load(f_model)\n",
    "    print(f\"Model berhasil dimuat dari: {MODEL_PATH}\")\n",
    "\n",
    "    with open(SCALER_PATH, 'rb') as f_scaler:\n",
    "        scaler = pickle.load(f_scaler)\n",
    "    print(f\"Scaler berhasil dimuat dari: {SCALER_PATH}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error saat memuat file model/scaler: {e}\")\n",
    "    print(\"Pastikan script train_model.py sudah dijalankan dan file .pkl ada di folder 'models'.\")\n",
    "    model = None\n",
    "    scaler = None\n",
    "except Exception as e:\n",
    "    print(f\"Terjadi error lain saat memuat file: {e}\")\n",
    "    model = None\n",
    "    scaler = None\n",
    "\n",
    "# === DEFINISIKAN MODEL INPUT (REQUEST BODY) MENGGUNAKAN PYDANTIC ===\n",
    "# Ini adalah fitur-fitur SEBELUM pra-pemrosesan (encoding dan scaling)\n",
    "# Nama field harus sesuai dengan apa yang diharapkan frontend\n",
    "# Kita pakai nilai contoh dari dataset Cleveland dan deskripsinya\n",
    "class HeartDiseaseInput(BaseModel):\n",
    "    age: int = Field(..., example=52, description=\"Umur pasien (tahun)\")\n",
    "    sex: Literal['Male', 'Female'] = Field(..., example='Male', description=\"Jenis kelamin pasien\")\n",
    "    cp: Literal['typical angina', 'atypical angina', 'non-anginal', 'asymptomatic'] = Field(..., example='asymptomatic', description=\"Tipe nyeri dada\")\n",
    "    trestbps: float = Field(..., example=120, description=\"Tekanan darah istirahat (mm Hg)\")\n",
    "    chol: float = Field(..., example=215, description=\"Kolesterol serum (mg/dl)\")\n",
    "    fbs: bool = Field(..., example=False, description=\"Gula darah puasa > 120 mg/dl (True/False)\")\n",
    "    restecg: Literal['normal', 'st-t abnormality', 'lv hypertrophy'] = Field(..., example='normal', description=\"Hasil elektrokardiografi istirahat\")\n",
    "    thalch: float = Field(..., example=150, description=\"Detak jantung maksimum tercapai\")\n",
    "    exang: bool = Field(..., example=False, description=\"Angina akibat olahraga (True/False)\")\n",
    "    oldpeak: float = Field(..., example=1.0, description=\"Depresi ST akibat olahraga relatif terhadap istirahat\")\n",
    "    slope: Literal['upsloping', 'flat', 'downsloping'] = Field(..., example='upsloping', description=\"Kemiringan segmen ST puncak olahraga\")\n",
    "    ca: float = Field(..., example=0.0, description=\"Jumlah pembuluh darah besar (0-3) yang diwarnai oleh fluoroskopi\") # Dulu int, tapi karena ada NaN, jadi float. Di sini kita asumsikan inputnya sudah bersih\n",
    "    thal: Literal['normal', 'fixed defect', 'reversable defect'] = Field(..., example='normal', description=\"Kelainan darah Thalassemia\")\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"age\": 63, \"sex\": \"Male\", \"cp\": \"typical angina\", \"trestbps\": 145.0, \"chol\": 233.0,\n",
    "                \"fbs\": True, \"restecg\": \"lv hypertrophy\", \"thalch\": 150.0, \"exang\": False,\n",
    "                \"oldpeak\": 2.3, \"slope\": \"downsloping\", \"ca\": 0.0, \"thal\": \"fixed defect\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "# === DAFTAR KOLOM YANG DIHARAPKAN MODEL SETELAH ENCODING ===\n",
    "# Ini HARUS SAMA PERSIS dengan urutan kolom X_train saat melatih model dan scaler\n",
    "# Ambil dari output X_train_scaled.columns.tolist() di train_model.py\n",
    "# Sesuaikan dengan nama kolom dummy yang benar dari proses get_dummies kamu\n",
    "EXPECTED_COLUMNS_AFTER_DUMMIES = [\n",
    "    'age', 'sex', 'trestbps', 'chol', 'fbs', 'thalch', 'exang', 'oldpeak', 'ca',\n",
    "    'cp_atypical angina', 'cp_non-anginal', 'cp_typical angina', # cp_asymptomatic adalah drop_first=True\n",
    "    'restecg_normal', 'restecg_st-t abnormality', # restecg_lv hypertrophy adalah drop_first=True (jika itu urutan pertama) atau perlu dicek lagi urutan kategori saat get_dummies\n",
    "    'slope_flat', 'slope_upsloping', # slope_downsloping adalah drop_first=True\n",
    "    'thal_normal', 'thal_reversable defect' # thal_fixed defect adalah drop_first=True\n",
    "]\n",
    "# PENTING: Verifikasi ulang nama kolom dummy ini berdasarkan output df.columns.tolist()\n",
    "# setelah pd.get_dummies(..., drop_first=True) di train_model.py mu!\n",
    "\n",
    "# === ENDPOINT PREDIKSI ===\n",
    "@app.post(\"/predict/\")\n",
    "async def predict_heart_disease(data_input: HeartDiseaseInput):\n",
    "    if not model or not scaler:\n",
    "        return {\"error\": \"Model atau scaler tidak berhasil dimuat. Cek log server.\"}\n",
    "\n",
    "    try:\n",
    "        # 1. Ubah data input Pydantic menjadi dictionary\n",
    "        input_dict = data_input.dict()\n",
    "\n",
    "        # 2. Buat DataFrame dari input_dict (hanya satu baris)\n",
    "        input_df_raw = pd.DataFrame([input_dict])\n",
    "\n",
    "        # 3. Lakukan pra-pemrosesan SAMA PERSIS seperti saat training:\n",
    "        #    a. Mapping 'sex'\n",
    "        input_df_processed = input_df_raw.copy()\n",
    "        input_df_processed['sex'] = input_df_processed['sex'].map({'Male': 1, 'Female': 0})\n",
    "        #    b. Mapping 'fbs' dan 'exang' (boolean ke int 0/1)\n",
    "        input_df_processed['fbs'] = input_df_processed['fbs'].astype(int)\n",
    "        input_df_processed['exang'] = input_df_processed['exang'].astype(int)\n",
    "\n",
    "        #    c. One-Hot Encoding untuk kolom kategorikal\n",
    "        #       PENTING: Harus menghasilkan kolom yang sama persis dengan saat training\n",
    "        #       Kita gunakan pd.get_dummies dan reindex untuk memastikan konsistensi\n",
    "        categorical_cols_api = ['cp', 'restecg', 'slope', 'thal']\n",
    "        input_df_processed = pd.get_dummies(input_df_processed, columns=categorical_cols_api, drop_first=True)\n",
    "        \n",
    "        # Reindex untuk memastikan semua kolom yang diharapkan model ada,\n",
    "        # dan urutannya benar. Kolom yang tidak ada di input_df_processed\n",
    "        # setelah get_dummies (karena inputnya hanya satu kategori) akan diisi 0.\n",
    "        input_df_final_features = input_df_processed.reindex(columns=EXPECTED_COLUMNS_AFTER_DUMMIES, fill_value=0)\n",
    "        \n",
    "        #    d. Scaling fitur menggunakan scaler yang sudah di-fit\n",
    "        #       Scaler di-fit pada semua kolom fitur (setelah encoding) saat training\n",
    "        scaled_features_np = scaler.transform(input_df_final_features)\n",
    "        #       Jika ingin tetap DataFrame (opsional, tapi baik untuk verifikasi nama fitur oleh model):\n",
    "        #       scaled_features_df = pd.DataFrame(scaled_features_np, columns=EXPECTED_COLUMNS_AFTER_DUMMIES)\n",
    "\n",
    "        # 4. Lakukan prediksi\n",
    "        prediction_proba = model.predict_proba(scaled_features_np) # Atau scaled_features_df jika dikonversi\n",
    "        prediction = model.predict(scaled_features_np)      # Atau scaled_features_df jika dikonversi\n",
    "\n",
    "        probability_class_1 = float(prediction_proba[0][1]) # Probabilitas kelas 1 (sakit)\n",
    "        predicted_class = int(prediction[0])                # Hasil kelas 0 atau 1\n",
    "\n",
    "        return {\n",
    "            \"prediction_label\": \"Risiko Penyakit Jantung\" if predicted_class == 1 else \"Risiko Rendah\",\n",
    "            \"predicted_class\": predicted_class,\n",
    "            \"probability_score_class_1\": probability_class_1,\n",
    "            \"detail_input\": input_dict # Mengembalikan input untuk verifikasi\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Terjadi kesalahan saat prediksi: {str(e)}\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
